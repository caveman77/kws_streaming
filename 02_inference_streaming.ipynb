{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 13:25:27.905965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@niveditha.itengineer/learn-how-to-setup-portaudio-and-pyaudio-in-ubuntu-to-play-with-speech-recognition-8d2fff660e94\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import timeit\n",
    "import python_speech_features\n",
    "#import RPi.GPIO as GPIO\n",
    "\n",
    "#from tflite_runtime.interpreter import Interpreter\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'input_audio', 'index': 0, 'shape': array([  1, 320], dtype=int32), 'shape_signature': array([  1, 320], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/speech_features/data_frame_1input_state', 'index': 1, 'shape': array([  1, 640], dtype=int32), 'shape_signature': array([  1, 640], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/svdf_0/depthwise_conv1d_6/depthwise_conv1d_6input_state', 'index': 2, 'shape': array([ 1,  4, 16], dtype=int32), 'shape_signature': array([ 1,  4, 16], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/svdf_1/depthwise_conv1d_7/depthwise_conv1d_7input_state', 'index': 3, 'shape': array([ 1, 10, 32], dtype=int32), 'shape_signature': array([ 1, 10, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/svdf_2/depthwise_conv1d_8/depthwise_conv1d_8input_state', 'index': 4, 'shape': array([ 1, 10, 32], dtype=int32), 'shape_signature': array([ 1, 10, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/svdf_3/depthwise_conv1d_9/depthwise_conv1d_9input_state', 'index': 5, 'shape': array([ 1, 10, 32], dtype=int32), 'shape_signature': array([ 1, 10, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/svdf_4/depthwise_conv1d_10/depthwise_conv1d_10input_state', 'index': 6, 'shape': array([ 1, 10, 64], dtype=int32), 'shape_signature': array([ 1, 10, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/svdf_5/depthwise_conv1d_11/depthwise_conv1d_11input_state', 'index': 7, 'shape': array([  1,  10, 128], dtype=int32), 'shape_signature': array([  1,  10, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'streaming/stream/stream/input_state', 'index': 8, 'shape': array([  1,   1, 128], dtype=int32), 'shape_signature': array([  1,   1, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "#debug_time = 1\n",
    "#debug_acc = 0\n",
    "#led_pin = 8\n",
    "#word_threshold = 0.5\n",
    "rec_duration = 0.02\n",
    "sample_rate = 16000\n",
    "\n",
    "num_channels = 1\n",
    "model_path = 'models3_30k/svdf/tflite_stream_state_external/stream_state_external.tflite'\n",
    "\n",
    "# Sliding window\n",
    "window = np.zeros(int(rec_duration * sample_rate) * 2)\n",
    "\n",
    "# GPIO \n",
    "#GPIO.setwarnings(False)\n",
    "#GPIO.setmode(GPIO.BOARD)\n",
    "#GPIO.setup(8, GPIO.OUT, initial=GPIO.LOW)\n",
    "\n",
    "# Load model (interpreter)\n",
    "#interpreter = Interpreter(model_path)\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 320], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "for s in range(len(input_details)):\n",
    "  inputs.append(np.zeros(input_details[s]['shape'], dtype=np.float32))\n",
    "\n",
    "input_details[0]['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimate (filter and downsample)\n",
    "def decimate(signal, old_fs, new_fs):\n",
    "    \n",
    "    # Check to make sure we're downsampling\n",
    "    if new_fs > old_fs:\n",
    "        print(\"Error: target sample rate higher than original\")\n",
    "        return signal, old_fs\n",
    "    \n",
    "    # We can only downsample by an integer factor\n",
    "    dec_factor = old_fs / new_fs\n",
    "    if not dec_factor.is_integer():\n",
    "        print(\"Error: can only decimate by integer factor\")\n",
    "        return signal, old_fs\n",
    "\n",
    "    # Do decimation\n",
    "    resampled_signal = scipy.signal.decimate(signal, int(dec_factor))\n",
    "\n",
    "    return resampled_signal, new_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets called every 0.5 seconds\n",
    "def sd_callback(rec, frames, time, status):   \n",
    "    #print('rec:', rec.shape) \n",
    "    # Remove 2nd dimension from recording sample\n",
    "    #rec = np.squeeze(rec)\n",
    "    rec = np.reshape(rec, (1,-1))\n",
    "\n",
    "    # set input audio data (by default input data at index 0)\n",
    "    interpreter.set_tensor(input_details[0]['index'], rec)\n",
    "\n",
    "    # set input states (index 1...)\n",
    "    for s in range(1, len(input_details)):\n",
    "        interpreter.set_tensor(input_details[s]['index'], inputs[s])\n",
    "\n",
    "    # run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # get output: classification\n",
    "    out_tflite = interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(start / 16000.0, np.argmax(out_tflite), np.max(out_tflite))\n",
    "\n",
    "    # get output states and set it back to input states\n",
    "    # which will be fed in the next inference cycle\n",
    "    for s in range(1, len(input_details)):\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "        inputs[s] = interpreter.get_tensor(output_details[s]['index'])\n",
    "\n",
    "    out_tflite_argmax = np.argmax(out_tflite)\n",
    "    if out_tflite_argmax>1:\n",
    "        print(out_tflite_argmax)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 320]\n",
      "[  1 640]\n",
      "[ 1  4 16]\n",
      "[ 1 10 32]\n",
      "[ 1 10 32]\n",
      "[ 1 10 32]\n",
      "[ 1 10 64]\n",
      "[  1  10 128]\n",
      "[  1   1 128]\n"
     ]
    }
   ],
   "source": [
    "reset_state = True\n",
    "\n",
    "# before processing new test sequence we can reset model state\n",
    "# if we reset model state then it is not real streaming mode\n",
    "if reset_state:\n",
    "  for s in range(len(input_details)):\n",
    "    print(input_details[s]['shape'])\n",
    "    inputs[s] = np.zeros(input_details[s]['shape'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels: 1 samplerate: 16000 blocksize: 320\n",
      "13\n",
      "13\n",
      "12\n",
      "18\n",
      "18\n",
      "18\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "4\n",
      "18\n",
      "13\n",
      "20\n",
      "13\n",
      "20\n",
      "20\n",
      "32\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "10\n",
      "19\n",
      "19\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26635/1764569225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     callback=sd_callback):\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start streaming from microphone\n",
    "print('channels:',num_channels, 'samplerate:',sample_rate, 'blocksize:', int(sample_rate * rec_duration))\n",
    "with sd.InputStream(channels=num_channels,\n",
    "                    samplerate=sample_rate,\n",
    "                    blocksize=int(sample_rate * rec_duration),\n",
    "                    callback=sd_callback):\n",
    "    while True:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
