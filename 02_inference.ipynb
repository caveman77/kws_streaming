{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OXYgXFeMgRep"
      },
      "source": [
        "Copyright 2019 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NcIzzCADklYm"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/google-research/google-research.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ngihcW7ckrDI"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "sys.path.append('./google-research')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y55h79H3XKSt"
      },
      "source": [
        "# Examples of streaming and non streaming inference with TF/TFlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fathHzuEgx8_"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yP5WBy5O8Za8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-18 10:37:01.720733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ]
        }
      ],
      "source": [
        "# TF streaming\n",
        "from kws_streaming.models import models\n",
        "from kws_streaming.models import utils\n",
        "from kws_streaming.layers.modes import Modes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wsUCmBzpk1jC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import logging\n",
        "from kws_streaming.models import model_params\n",
        "from kws_streaming.train import model_flags\n",
        "from kws_streaming.train import test\n",
        "from kws_streaming.models import utils\n",
        "from kws_streaming import data\n",
        "tf1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jow_HMLAU7LR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-18 10:37:10.998929: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-18 10:37:11.000783: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2024-02-18 10:37:11.007529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2024-02-18 10:37:11.025028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-02-18 10:37:11.025421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4090 computeCapability: 8.9\n",
            "coreClock: 2.52GHz coreCount: 128 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 938.86GiB/s\n",
            "2024-02-18 10:37:11.025434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2024-02-18 10:37:11.035666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2024-02-18 10:37:11.035689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2024-02-18 10:37:11.041024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2024-02-18 10:37:11.043207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2024-02-18 10:37:11.043568: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:\n",
            "2024-02-18 10:37:11.046670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2024-02-18 10:37:11.047646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2024-02-18 10:37:11.047655: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-02-18 10:37:11.101456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2024-02-18 10:37:11.101477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2024-02-18 10:37:11.101483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n"
          ]
        }
      ],
      "source": [
        "config = tf1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf1.Session(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zMdTK10tL2Dz"
      },
      "outputs": [],
      "source": [
        "# general imports\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import scipy as scipy\n",
        "import scipy.io.wavfile as wav\n",
        "import scipy.signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L_F-8OFCU7La"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xHTcbg_ao586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_10728/2804348034.py:3: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-18 10:37:19.466785: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2024-02-18 10:37:19.466946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-02-18 10:37:19.467075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4090 computeCapability: 8.9\n",
            "coreClock: 2.52GHz coreCount: 128 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 938.86GiB/s\n",
            "2024-02-18 10:37:19.467096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2024-02-18 10:37:19.467111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2024-02-18 10:37:19.467118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2024-02-18 10:37:19.467125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2024-02-18 10:37:19.467131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2024-02-18 10:37:19.467617: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:\n",
            "2024-02-18 10:37:19.467628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2024-02-18 10:37:19.467635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2024-02-18 10:37:19.467639: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-02-18 10:37:19.467852: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2024-02-18 10:37:19.467865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2024-02-18 10:37:19.467870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
            "/mnt/disk0shared/bdjola/Documents/Technique/DevML/kws_streaming2/kws_streaming/.venv/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        }
      ],
      "source": [
        "tf1.reset_default_graph()\n",
        "sess = tf1.Session()\n",
        "tf1.keras.backend.set_session(sess)\n",
        "tf1.keras.backend.set_learning_phase(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ylPGCTPLh41F"
      },
      "source": [
        "## Load wav file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "b8Bvq7XacsOu"
      },
      "outputs": [],
      "source": [
        "def waveread_as_pcm16(filename):\n",
        "  \"\"\"Read in audio data from a wav file.  Return d, sr.\"\"\"\n",
        "  with open(filename, 'rb') as file_handle:\n",
        "  #with tf.io.gfile.GFile(filename, 'rb') as file_handle:\n",
        "    samplerate, wave_data = wav.read(file_handle)\n",
        "  # Read in wav file.\n",
        "  return wave_data, samplerate\n",
        "\n",
        "def wavread_as_float(filename, target_sample_rate=16000):\n",
        "  \"\"\"Read in audio data from a wav file.  Return d, sr.\"\"\"\n",
        "  wave_data, samplerate = waveread_as_pcm16(filename)\n",
        "  desired_length = int(\n",
        "      round(float(len(wave_data)) / samplerate * target_sample_rate))\n",
        "  wave_data = scipy.signal.resample(wave_data, desired_length)\n",
        "\n",
        "  # Normalize short ints to floats in range [-1..1).\n",
        "  data = np.array(wave_data, np.float32) / 32768.0\n",
        "  return data, target_sample_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e6MDIFztU7Lp"
      },
      "outputs": [],
      "source": [
        "# set PATH to data sets (for example to speech commands V2):\n",
        "# it can be downloaded from\n",
        "# https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "# if you run 00_check-data.ipynb then data2 should be located in the current folder\n",
        "current_dir = os.getcwd()\n",
        "DATA_PATH = os.path.join(current_dir, \"data2/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/disk0shared/bdjola/Documents/Technique/DevML/kws_streaming2/kws_streaming/data2/'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TYj0JGeHhtqc"
      },
      "outputs": [],
      "source": [
        "# Set path to wav file for testing.\n",
        "wav_file = os.path.join(DATA_PATH, \"left/0a2b400e_nohash_0.wav\")\n",
        "\n",
        "# read audio file\n",
        "wav_data, samplerate = wavread_as_float(wav_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "00CBA81RU7Lz"
      },
      "outputs": [],
      "source": [
        "assert samplerate == 16000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U7VYKfWoh_3-"
      },
      "outputs": [],
      "source": [
        "# for simple test instead of reading wav - just generate cos\n",
        "# samplerate = 16000\n",
        "# wav_data = np.cos(2.0*np.pi*8.0*np.arange(samplerate)/samplerate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jNiuJTvXiF1J"
      },
      "outputs": [],
      "source": [
        "#assert samplerate == 16000\n",
        "#sound.Play(wav_data, samplerate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "r2yeKkLsiRWJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8a82aa0f10>]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(wav_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5_wbAZ3vhQh1"
      },
      "source": [
        "## Prepare batched model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SYl2VSAhU7L_"
      },
      "outputs": [],
      "source": [
        "# Set path to model weights and model parameters models trained on data set V2 can be downloaded from\n",
        "# https://storage.googleapis.com/kws_models/models2.zip\n",
        "# or from https://storage.googleapis.com/kws_models/models2_30k.zip\n",
        "#MODEL_URL = \"https://storage.googleapis.com/kws_models/models2_30k.zip\"\n",
        "#base_name = os.path.basename(MODEL_URL)\n",
        "MODELS_PATH = current_dir\n",
        "#base_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mH-fyuESU7MD"
      },
      "outputs": [],
      "source": [
        "# it can take some time to download 2.3GB. After unpacking total size is 5.4GB\n",
        "#arch_file_name = os.path.join(MODELS_PATH, base_name)\n",
        "#if not os.path.isfile(arch_file_name):\n",
        "  # download data\n",
        "  #if sys.version_info >= (2, 5):\n",
        "  #  file_path = urllib.request.urlretrieve(MODEL_URL, filename=arch_file_name)[0]\n",
        "  #else:\n",
        "  #  file_path = urllib.urlretrieve(MODEL_URL, filename=arch_file_name)[0]\n",
        "\n",
        "  # unpack it\n",
        "  #file_name, file_extension = os.path.splitext(base_name)\n",
        "  #with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "  #  zip_ref.extractall(MODELS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/disk0shared/bdjola/Documents/Technique/DevML/kws_streaming2/kws_streaming'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODELS_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XDZTRXCxU7MF"
      },
      "outputs": [],
      "source": [
        "file_name='models'\n",
        "train_dir = os.path.join(MODELS_PATH, file_name, 'svdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/disk0shared/bdjola/Documents/Technique/DevML/kws_streaming2/kws_streaming/models/svdf'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e2f-1Ioqbn4G"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<string>, line 1)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/mnt/disk0shared/bdjola/Documents/Technique/DevML/kws_streaming2/kws_streaming/.venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_10728/2556346056.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    flags = eval(flags_txt)\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <kws_streaming.models.model_params.Params object at 0x7fdc182ed810>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# load command line command flags which were use for model creation/training\n",
        "from argparse import Namespace\n",
        "#with tf.compat.v1.gfile.Open(os.path.join(train_dir, 'flags.txt'), 'r') as fd:\n",
        "#with open(os.path.join(train_dir, 'flags.txt'), 'r') as fd:\n",
        "#  flags_txt = fd.read()\n",
        "#flags = eval(flags_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<kws_streaming.models.model_params.Params object at 0x7fdc182ed810>\\n'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flags_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I2x6dAhgU7ML"
      },
      "outputs": [],
      "source": [
        "# below is another way of reading flags - through json\n",
        "with tf.compat.v1.gfile.Open(os.path.join(train_dir, 'flags.json'), 'r') as fd:\n",
        "   flags_json = json.load(fd)\n",
        "\n",
        "class DictStruct(object):\n",
        "   def __init__(self, **entries):\n",
        "     self.__dict__.update(entries)\n",
        "\n",
        "flags = DictStruct(**flags_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PSfkGIgAU7MO"
      },
      "outputs": [],
      "source": [
        "flags.data_dir = DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U1al1r1PU7MR"
      },
      "outputs": [],
      "source": [
        "# pad input audio with zeros, so that audio len = flags.desired_samples\n",
        "padded_wav = np.pad(wav_data, (0, flags.desired_samples-len(wav_data)), 'constant')\n",
        "\n",
        "input_data = np.expand_dims(padded_wav, 0)\n",
        "input_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gkWTgtOWU7MT"
      },
      "outputs": [],
      "source": [
        "# prepare mapping of index to word\n",
        "audio_processor = data.input_data.AudioProcessor(flags)\n",
        "index_to_label = {}\n",
        "# labels used for training\n",
        "for word in audio_processor.word_to_index.keys():\n",
        "  if audio_processor.word_to_index[word] == data.input_data.SILENCE_INDEX:\n",
        "    index_to_label[audio_processor.word_to_index[word]] = data.input_data.SILENCE_LABEL\n",
        "  elif audio_processor.word_to_index[word] == data.input_data.UNKNOWN_WORD_INDEX:\n",
        "    index_to_label[audio_processor.word_to_index[word]] = data.input_data.UNKNOWN_WORD_LABEL\n",
        "  else:\n",
        "    index_to_label[audio_processor.word_to_index[word]] = word\n",
        "\n",
        "# training labels\n",
        "index_to_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WlGR0oOxnizg"
      },
      "outputs": [],
      "source": [
        "# we can create a dummy model\n",
        "# flags = model_params.HOTWORD_MODEL_PARAMS['gru']\n",
        "# flags = model_flags.update_flags(flags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wsGDG4A0cIMO"
      },
      "outputs": [],
      "source": [
        "# create model with flag's parameters\n",
        "model_non_stream_batch = models.MODELS[flags.model_name](flags)\n",
        "\n",
        "# load model's weights\n",
        "weights_name = 'best_weights'\n",
        "model_non_stream_batch.load_weights(os.path.join(train_dir, weights_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dsWLekwbkdTo"
      },
      "outputs": [],
      "source": [
        "#model_non_stream_batch.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QVhESthmMl0X"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model_non_stream_batch,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RIr1DWLisMu9"
      },
      "source": [
        "## Run inference with TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "456ynjRxmdVc"
      },
      "source": [
        "### TF Run non streaming inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-vJpOCJClDK5"
      },
      "outputs": [],
      "source": [
        "# convert model to inference mode with batch one\n",
        "inference_batch_size = 1\n",
        "tf.keras.backend.set_learning_phase(0)\n",
        "flags.batch_size = inference_batch_size  # set batch size\n",
        "\n",
        "model_non_stream = utils.to_streaming_inference(model_non_stream_batch, flags, Modes.NON_STREAM_INFERENCE)\n",
        "#model_non_stream.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O1gOGQjWMufh"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model_non_stream,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nPUfT4a4lxIj"
      },
      "outputs": [],
      "source": [
        "predictions = model_non_stream.predict(input_data)\n",
        "predicted_labels = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "63sisD1hl7jz"
      },
      "outputs": [],
      "source": [
        "predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rBhLA1OZmQxj"
      },
      "outputs": [],
      "source": [
        "index_to_label[predicted_labels[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZVFoVdYSpnL_"
      },
      "source": [
        "### TF Run streaming inference with internal state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cgcpcrASquAY"
      },
      "outputs": [],
      "source": [
        "# convert model to streaming mode\n",
        "flags.batch_size = inference_batch_size  # set batch size\n",
        "\n",
        "model_stream = utils.to_streaming_inference(model_non_stream_batch, flags, Modes.STREAM_INTERNAL_STATE_INFERENCE)\n",
        "#model_stream.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BNtgTOBCM06v"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model_stream,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7NOG8wrYpnnq"
      },
      "outputs": [],
      "source": [
        "# run streaming inference\n",
        "start = 0\n",
        "end = flags.window_stride_samples\n",
        "while end <= input_data.shape[1]:\n",
        "  stream_update = input_data[:, start:end]\n",
        "\n",
        "  # get new frame from stream of data\n",
        "  stream_output_prediction = model_stream.predict(stream_update)\n",
        "  stream_output_arg = np.argmax(stream_output_prediction)\n",
        "\n",
        "  # update indexes of streamed updates\n",
        "  start = end\n",
        "  end = start + flags.window_stride_samples\n",
        "\n",
        "stream_output_arg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S-xeXPhAqC20"
      },
      "outputs": [],
      "source": [
        "index_to_label[stream_output_arg]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F5WYgOtSqrQb"
      },
      "source": [
        "### TF Run streaming inference with external state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2hTLEY1qq_ig"
      },
      "outputs": [],
      "source": [
        "# convert model to streaming mode\n",
        "flags.batch_size = inference_batch_size  # set batch size\n",
        "\n",
        "model_stream = utils.to_streaming_inference(model_non_stream_batch, flags, Modes.STREAM_EXTERNAL_STATE_INFERENCE)\n",
        "#model_stream.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AyeABeg9Mbf6"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model_stream,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RISdLTnmqrcA"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = []\n",
        "for s in range(len(model_stream.inputs)):\n",
        "  inputs.append(np.zeros(model_stream.inputs[s].shape, dtype=np.float32))\n",
        "\n",
        "reset_state = True\n",
        "\n",
        "if reset_state:\n",
        "  for s in range(len(model_stream.inputs)):\n",
        "    inputs[s] = np.zeros(model_stream.inputs[s].shape, dtype=np.float32)\n",
        "\n",
        "start = 0\n",
        "end = flags.window_stride_samples\n",
        "while end <= input_data.shape[1]:\n",
        "  # get new frame from stream of data\n",
        "  stream_update = input_data[:, start:end]\n",
        "\n",
        "  # update indexes of streamed updates\n",
        "  start = end\n",
        "  end = start + flags.window_stride_samples\n",
        "\n",
        "  # set input audio data (by default input data at index 0)\n",
        "  inputs[0] = stream_update\n",
        "\n",
        "  # run inference\n",
        "  outputs = model_stream.predict(inputs)\n",
        "\n",
        "  # get output states and set it back to input states\n",
        "  # which will be fed in the next inference cycle\n",
        "  for s in range(1, len(model_stream.inputs)):\n",
        "    inputs[s] = outputs[s]\n",
        "\n",
        "  stream_output_arg = np.argmax(outputs[0])\n",
        "stream_output_arg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "u6p1xubwrYyo"
      },
      "outputs": [],
      "source": [
        "index_to_label[stream_output_arg]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KAJs5dBXsYCa"
      },
      "source": [
        "## Run inference with TFlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z5qmO5KrU7NP"
      },
      "source": [
        "### Run non streaming inference with TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "88bclN4rtu-5"
      },
      "outputs": [],
      "source": [
        "# path = os.path.join(train_dir, 'tflite_non_stream')\n",
        "# tflite_model_name = 'non_stream.tflite'\n",
        "\n",
        "tflite_non_streaming_model = utils.model_to_tflite(sess, model_non_stream, flags, Modes.NON_STREAM_INFERENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VZgH11_0u2ZN"
      },
      "outputs": [],
      "source": [
        "# prepare TFLite interpreter\n",
        "# with tf.io.gfile.Open(os.path.join(path, tflite_model_name), 'rb') as f:\n",
        "#   model_content = f.read()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_non_streaming_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "inputs = []\n",
        "for s in range(len(input_details)):\n",
        "  inputs.append(np.zeros(input_details[s]['shape'], dtype=np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3J2n7VB5JxV6"
      },
      "outputs": [],
      "source": [
        "padded_input = np.zeros((1, 16000), dtype=np.float32)\n",
        "padded_input[:, :input_data.shape[1]] = input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TXqHxLcVregL"
      },
      "outputs": [],
      "source": [
        "# set input audio data (by default input data at index 0)\n",
        "interpreter.set_tensor(input_details[0]['index'], padded_input.astype(np.float32))\n",
        "\n",
        "# run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# get output: classification\n",
        "out_tflite = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "out_tflite_argmax = np.argmax(out_tflite)\n",
        "\n",
        "out_tflite_argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KbIB3zaiKEru"
      },
      "outputs": [],
      "source": [
        "print(out_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1vOhJRnCU7Nf"
      },
      "outputs": [],
      "source": [
        "index_to_label[out_tflite_argmax]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xNaUWgivuatL"
      },
      "source": [
        "### Run streaming inference with TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "csQWZo4BuqEB"
      },
      "outputs": [],
      "source": [
        "# path = os.path.join(train_dir, 'tflite_stream_state_external')\n",
        "# tflite_model_name = 'stream_state_external.tflite'\n",
        "\n",
        "tflite_streaming_model = utils.model_to_tflite(sess, model_non_stream, flags, Modes.STREAM_EXTERNAL_STATE_INFERENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "a4wAZqYouyob"
      },
      "outputs": [],
      "source": [
        "# with tf.io.gfile.Open(os.path.join(path, tflite_model_name), 'rb') as f:\n",
        "#   model_content = f.read()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_streaming_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "inputs = []\n",
        "for s in range(len(input_details)):\n",
        "  inputs.append(np.zeros(input_details[s]['shape'], dtype=np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "03QCq1nfVUWW"
      },
      "outputs": [],
      "source": [
        "input_details[0]['shape']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WKudF1Zyud2-"
      },
      "outputs": [],
      "source": [
        "reset_state = True\n",
        "\n",
        "# before processing new test sequence we can reset model state\n",
        "# if we reset model state then it is not real streaming mode\n",
        "if reset_state:\n",
        "  for s in range(len(input_details)):\n",
        "    print(input_details[s]['shape'])\n",
        "    inputs[s] = np.zeros(input_details[s]['shape'], dtype=np.float32)\n",
        "\n",
        "start = 0\n",
        "end = flags.window_stride_samples\n",
        "while end <= input_data.shape[1]:\n",
        "  stream_update = input_data[:, start:end]\n",
        "  stream_update = stream_update.astype(np.float32)\n",
        "\n",
        "  # update indexes of streamed updates\n",
        "  start = end\n",
        "  end = start + flags.window_stride_samples\n",
        "\n",
        "  # set input audio data (by default input data at index 0)\n",
        "  interpreter.set_tensor(input_details[0]['index'], stream_update)\n",
        "\n",
        "  # set input states (index 1...)\n",
        "  for s in range(1, len(input_details)):\n",
        "    interpreter.set_tensor(input_details[s]['index'], inputs[s])\n",
        "\n",
        "  # run inference\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # get output: classification\n",
        "  out_tflite = interpreter.get_tensor(output_details[0]['index'])\n",
        "  #print(start / 16000.0, np.argmax(out_tflite), np.max(out_tflite))\n",
        "\n",
        "  # get output states and set it back to input states\n",
        "  # which will be fed in the next inference cycle\n",
        "  for s in range(1, len(input_details)):\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    inputs[s] = interpreter.get_tensor(output_details[s]['index'])\n",
        "\n",
        "  out_tflite_argmax = np.argmax(out_tflite)\n",
        "out_tflite_argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yWy_BiepFFSX"
      },
      "outputs": [],
      "source": [
        "print(out_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QSa7AX1GvReF"
      },
      "outputs": [],
      "source": [
        "index_to_label[out_tflite_argmax]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WVQZXLyDU7N3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "02_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
